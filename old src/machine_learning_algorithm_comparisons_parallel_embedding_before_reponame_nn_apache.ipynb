{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b20cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "enhancement    37586\n",
      "bug            32864\n",
      "clean          17263\n",
      "performance     5392\n",
      "refactor        4596\n",
      "Name: count, dtype: int64\n",
      "labels\n",
      "enhancement    37586\n",
      "bug            32864\n",
      "clean          17263\n",
      "Name: count, dtype: int64\n",
      "labels\n",
      "bug            17934\n",
      "enhancement    16113\n",
      "clean          15336\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc136b07de804c22b05f714ed442736d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46008 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for XGBoost:\n",
      "  Accuracy: 0.8016735492284286\n",
      "  Precision: 0.8031687857152253\n",
      "  Recall: 0.8002905411588283\n",
      "  F1 Score: 0.8008573382120886\n",
      "Metrics for RandomForest:\n",
      "  Accuracy: 0.7663551401869159\n",
      "  Precision: 0.770280482587046\n",
      "  Recall: 0.7653462344278464\n",
      "  F1 Score: 0.7668120306411925\n",
      "Metrics for CatBoost:\n",
      "  Accuracy: 0.7475548793740491\n",
      "  Precision: 0.7582962695078966\n",
      "  Recall: 0.7453700971733247\n",
      "  F1 Score: 0.745897571672729\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 195990\n",
      "[LightGBM] [Info] Number of data points in the train set: 36806, number of used features: 818\n",
      "[LightGBM] [Info] Start training from score -1.091762\n",
      "[LightGBM] [Info] Start training from score -1.103487\n",
      "[LightGBM] [Info] Start training from score -1.100625\n",
      "Metrics for LightGBM:\n",
      "  Accuracy: 0.8010215170615084\n",
      "  Precision: 0.8036682091889573\n",
      "  Recall: 0.7993068517771426\n",
      "  F1 Score: 0.7994098054386592\n",
      "Metrics for AdaBoost:\n",
      "  Accuracy: 0.7186481199739188\n",
      "  Precision: 0.7182027336658958\n",
      "  Recall: 0.7169077617304517\n",
      "  F1 Score: 0.7171621784701719\n",
      "Metrics for SVM:\n",
      "  Accuracy: 0.7704846772440773\n",
      "  Precision: 0.7689523077300139\n",
      "  Recall: 0.7689601766646779\n",
      "  F1 Score: 0.7686994946969702\n",
      "Metrics for KNN:\n",
      "  Accuracy: 0.7914583786133449\n",
      "  Precision: 0.790167740357362\n",
      "  Recall: 0.7906722647518288\n",
      "  F1 Score: 0.7901172952034411\n",
      "Metrics for NaiveBayes:\n",
      "  Accuracy: 0.6386655074983699\n",
      "  Precision: 0.7400673721340488\n",
      "  Recall: 0.6332047695312969\n",
      "  F1 Score: 0.6037593869088793\n",
      "Metrics for LogisticRegression:\n",
      "  Accuracy: 0.7680938926320365\n",
      "  Precision: 0.765977279516722\n",
      "  Recall: 0.7663679378283804\n",
      "  F1 Score: 0.7655445607020203\n",
      "\n",
      "All Model Metrics:\n",
      "XGBoost: {'Accuracy': 0.8016735492284286, 'Precision': 0.8031687857152253, 'Recall': 0.8002905411588283, 'F1 Score': 0.8008573382120886}\n",
      "RandomForest: {'Accuracy': 0.7663551401869159, 'Precision': 0.770280482587046, 'Recall': 0.7653462344278464, 'F1 Score': 0.7668120306411925}\n",
      "CatBoost: {'Accuracy': 0.7475548793740491, 'Precision': 0.7582962695078966, 'Recall': 0.7453700971733247, 'F1 Score': 0.745897571672729}\n",
      "LightGBM: {'Accuracy': 0.8010215170615084, 'Precision': 0.8036682091889573, 'Recall': 0.7993068517771426, 'F1 Score': 0.7994098054386592}\n",
      "AdaBoost: {'Accuracy': 0.7186481199739188, 'Precision': 0.7182027336658958, 'Recall': 0.7169077617304517, 'F1 Score': 0.7171621784701719}\n",
      "SVM: {'Accuracy': 0.7704846772440773, 'Precision': 0.7689523077300139, 'Recall': 0.7689601766646779, 'F1 Score': 0.7686994946969702}\n",
      "KNN: {'Accuracy': 0.7914583786133449, 'Precision': 0.790167740357362, 'Recall': 0.7906722647518288, 'F1 Score': 0.7901172952034411}\n",
      "NaiveBayes: {'Accuracy': 0.6386655074983699, 'Precision': 0.7400673721340488, 'Recall': 0.6332047695312969, 'F1 Score': 0.6037593869088793}\n",
      "LogisticRegression: {'Accuracy': 0.7680938926320365, 'Precision': 0.765977279516722, 'Recall': 0.7663679378283804, 'F1 Score': 0.7655445607020203}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/code1001/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from utils import prepare_dataframe, load_embeddings_from_directory_for_df\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Veri hazırlığı\n",
    "embedding_directory = 'embeddings/GCB_Pooler_embeddings_patch_before_largewithcodedata_Xlimit3label'\n",
    "df = prepare_dataframe(\"merged.csv\", False, False)\n",
    "resulting_label_count = df['labels'].nunique()\n",
    "\n",
    "# Sadece apache repoları seçiliyor\n",
    "df = df[df['full_repo_name'].str.startswith('apache', na=False)]\n",
    "\n",
    "# Label frekanslarını görüntüleme\n",
    "label_counts = df['labels'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Test için veri setini dengeleme\n",
    "label_enh = df[df['labels'] == 'enhancement']\n",
    "label_bug = df[df['labels'] == 'bug']\n",
    "label_cln = df[df['labels'] == 'clean']\n",
    "\n",
    "min_samples = min(len(label_enh), len(label_bug), len(label_cln))\n",
    "sampled_enh = label_enh.sample(n=min_samples, random_state=1)\n",
    "sampled_bug = label_bug.sample(n=min_samples, random_state=1)\n",
    "sampled_cln = label_cln.sample(n=min_samples, random_state=1)\n",
    "df = pd.concat([sampled_enh, sampled_bug, sampled_cln])\n",
    "\n",
    "# One-hot encoding işlemi\n",
    "df_encoded_labels = pd.get_dummies(df, columns=['labels'])\n",
    "df_encoded_repo = pd.get_dummies(df, columns=['full_repo_name'])\n",
    "\n",
    "# Özellikler ve etiketler\n",
    "X_repo = df_encoded_repo.drop(columns=['labels', 'patch', 'index']).astype(int)\n",
    "y = df_encoded_labels.drop(columns=['patch', 'full_repo_name', 'index']).astype(int)\n",
    "\n",
    "# Tüm embedding ve repo_name_tensor verilerini yükleyip birleştirme\n",
    "df['label_tensor'] = [torch.tensor(row, dtype=torch.float32) for row in y.values]\n",
    "df['repo_name_tensor'] = [torch.tensor(row, dtype=torch.float32) for row in X_repo.values]\n",
    "df = df.drop(columns=['full_repo_name', 'labels', 'patch'])\n",
    "\n",
    "# Embedding'leri yükleme\n",
    "df = load_embeddings_from_directory_for_df(directory_path=embedding_directory, df=df)\n",
    "df['embedding'] = df['embedding'].apply(lambda x: x.numpy() if isinstance(x, torch.Tensor) else x)\n",
    "df['repo_name_tensor'] = df['repo_name_tensor'].apply(lambda x: x.numpy() if isinstance(x, torch.Tensor) else x)\n",
    "\n",
    "# Özellikleri birleştirme ve normalize etme\n",
    "X = np.vstack(df.apply(lambda row: np.concatenate([row['embedding'], row['repo_name_tensor']]), axis=1))\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Label tensor'leri argmax ile sınıf etiketine çevirme\n",
    "y = df['label_tensor'].apply(lambda x: x.numpy().argmax() if isinstance(x, torch.Tensor) else x).values\n",
    "\n",
    "# Veriyi eğitim ve test setlerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Modelleri tanımlıyoruz\n",
    "models = [\n",
    "    (\"XGBoost\", xgb.XGBClassifier(objective=\"multi:softmax\", num_class=3, eval_metric=\"mlogloss\")),\n",
    "    (\"RandomForest\", RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    (\"CatBoost\", CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, verbose=0)),\n",
    "    (\"LightGBM\", LGBMClassifier(num_class=3)),\n",
    "    (\"AdaBoost\", AdaBoostClassifier(n_estimators=100, random_state=42)),\n",
    "    (\"SVM\", SVC(decision_function_shape='ovo', kernel='linear', random_state=42)),\n",
    "    (\"KNN\", KNeighborsClassifier(n_neighbors=5)),\n",
    "    (\"NaiveBayes\", GaussianNB()),\n",
    "    (\"LogisticRegression\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "]\n",
    "\n",
    "# Modellerin doğruluk, precision, recall ve f1 skorlarını saklamak için bir sözlük\n",
    "metrics = {}\n",
    "\n",
    "# Modelleri eğitip tahmin sürelerini hesapla\n",
    "for model_name, model in models:\n",
    "    # Modeli eğit\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Tahmin süresini ölç\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)  # Tahmin yap\n",
    "    end_time = time.time()\n",
    "    prediction_time = end_time - start_time  # Tahmin süresi\n",
    "\n",
    "    # Metrikleri hesapla\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Metrikleri ve tahmin süresini sakla\n",
    "    metrics[model_name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Prediction Time (s)\": prediction_time\n",
    "    }\n",
    "\n",
    "    # Sonuçları yazdır\n",
    "    print(f\"Metrics for {model_name}:\")\n",
    "    print(f\"  Accuracy: {accuracy}\")\n",
    "    print(f\"  Precision: {precision}\")\n",
    "    print(f\"  Recall: {recall}\")\n",
    "    print(f\"  F1 Score: {f1}\")\n",
    "    print(f\"  Prediction Time (s): {prediction_time:.4f}\")\n",
    "\n",
    "# Tüm sonuçları görüntüleme\n",
    "print(\"\\nAll Model Metrics:\")\n",
    "for model_name, model_metrics in metrics.items():\n",
    "    print(f\"{model_name}: {model_metrics}\")\n",
    "    \n",
    "\n",
    "# Metrikleri CSV dosyasına kaydetme\n",
    "output_file = \"model_metrics.csv\"\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Başlıkları yaz\n",
    "    writer.writerow([\"Model Name\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Prediction Time (s)\"])\n",
    "    # Her modelin metriklerini yaz\n",
    "    for model_name, model_metrics in metrics.items():\n",
    "        writer.writerow([\n",
    "            model_name,\n",
    "            model_metrics[\"Accuracy\"],\n",
    "            model_metrics[\"Precision\"],\n",
    "            model_metrics[\"Recall\"],\n",
    "            model_metrics[\"F1 Score\"],\n",
    "            model_metrics[\"Prediction Time (s)\"]\n",
    "        ])\n",
    "\n",
    "print(f\"\\nMetrics saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ce6d1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Eğitilmiş modeller ile confusion matrix'i sonradan hesaplama ve görselleştirme\u001b[39;00m\n\u001b[1;32m      7\u001b[0m confusion_matrices \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      9\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)  \u001b[38;5;66;03m# Test verisi üzerinde tahmin yap\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "\n",
    "# Eğitilmiş modeller ile confusion matrix'i sonradan hesaplama ve görselleştirme\n",
    "confusion_matrices = {}\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test)  # Test verisi üzerinde tahmin yap\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices[model_name] = cm  # Confusion matrix'i sakla\n",
    "\n",
    "# Confusion matrix'leri görselleştirme\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15))\n",
    "fig.suptitle(\"Confusion Matrices for Trained Models\", fontsize=20)\n",
    "\n",
    "for ax, (model_name, cm) in zip(axes.flatten(), confusion_matrices.items()):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "    ax.set_title(f\"{model_name} Confusion Matrix\")\n",
    "    ax.set_xlabel(\"Predicted Label\")\n",
    "    ax.set_ylabel(\"True Label\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to fit titles\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713482f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
